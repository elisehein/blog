---
layout: post
title:  "Usability for programmers: dissertation kickoff"
date:   2016-02-10 19:56:00 +0000
categories:
- technical
tags: 
- msc
- dev ux
- ux research methods
---

Another two months to go and I will have finished all of the taught modules
for my master's degree in HCI. Next up --Â the dissertation. All I need is a
topic.

Initially I thought about somehow combining HCI with linguistics or NLP. For
example, as I learnt from [@karlsutt](http://twitter.com/karlsutt) (who has
recently been vocal about the benefits of functional programming), developers
won't realise how hungry they are for accessible error messages until
they've worked with Haskell or [Elm](http://elm-lang.org), a functional
language that compiles to Javascript. In addition to (supposedly) eliminating
run-time exceptions, Elm aims to make the programmer happy when debugging by
producing more comprehensive and "human" error messages than what we've so far
been exposed to. 

Putting such claims under scrutiny and conducting a more general study of what
makes the difference between a user-friendly error message and one that is
frustrating would certainly have been interesting. But looking into it
further, the common ground that error messages share with linguistics on the
one hand and HCI on the other is too far-fetched to justify. 

Luckily, the idea led to a whole new area of potentially impactful research --
**usability for programmers**. This, I think, has an almost romantic ring to
it. If UX is all about putting the layman front and centre when designing
technology, then what of the neglected developer, deciphering compiler errors,
trying to make sense of `git rebase`, and battling the RSI that gets worse
every time they must reach the tiny ESC key with their pinky because Caps Lock
is already remapped to Ctrl to make Emacs keybindings more ergonomic...

As it turns out, the programmer is not as neglected as one might think. An
initial search for "debugging strategies user study" led to a range of
specialised research from [copy &
paste](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=1334896&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D1334896)
practices to facilitating [feature location in large codebases](How developers
perform feature location tasks: a human-centric and process-oriented
exploratory study), accessible directoy structuring, [automated debugging
tools](http://dl.acm.org/citation.cfm?id=2001445), as well as more social
issues such as code ownership and the impact of interruptions to development
tasks.

I have narrowed the choice down to four areas:

1. Causes behind copy & paste errors, and tool design to prevent them
2. A review of debugging strategies: from fault identification to correction
3. Visualising git repositories to facilitate comprehension of version control
4. Feature location in large/unfamiliar codebases

One of these will become the staple food of my mental diet for the better half
of the following year.

In addition to the research itself, the choice of methods and how they are
carried out in practice in this area can be a valuable contribution to the
field. Ethnographic studies may have their roots in the African bush where
missionaries and anthropologists dutifully noted down cultural peculiarities,
but they have been relatively successfully adapted to fit user research in
HCI. But where the user is a programmer, many of the best practices for
conducting usability studies may well blow up in your face. For example, how
do we interpret eye-tracking data when a developer is scanning code? Is it
even significant? How do you interpret qualitative data from a think-aloud
session with a solo programmer when the nature of a think-aloud study will
transform the session into what is essentially pair programming? 

Don't even get me started on diary studies.

